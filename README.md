# ğŸ§  The Memory Twin

> **Agente de Memoria EpisÃ³dica para Desarrollo de Software**

Sistema de arquitectura dual (Escriba + OrÃ¡culo) diseÃ±ado para mitigar la "amnesia tÃ©cnica" en equipos de desarrollo. Captura, procesa y almacena el razonamiento ("thinking") detrÃ¡s de las decisiones de cÃ³digo tomadas por asistentes de IA.

## ğŸ¯ Valor Diferencial

- **Memoria de Razonamiento**: Captura el "porquÃ©" (thinking), no solo el "quÃ©" (cÃ³digo final)
- **AgnÃ³stico del Modelo**: Funciona con cualquier asistente (Copilot, Claude, Cursor)
- **Onboarding Automatizado**: Reduce el tiempo de aprendizaje en proyectos legacy
- **RAG sobre Decisiones**: Consulta contextual sobre la historia tÃ©cnica
- **Colaborativo**: Soporte para base de datos compartida en equipos

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Memory Twin                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     ESCRIBA            â”‚           ORÃCULO                  â”‚
â”‚   (Backend/Ingesta)    â”‚       (Frontend/Consulta)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Captura thinking     â”‚ â€¢ Q&A Contextual (RAG)             â”‚
â”‚ â€¢ Procesa con LLM      â”‚ â€¢ Timeline de Decisiones           â”‚
â”‚ â€¢ Genera embeddings    â”‚ â€¢ Lecciones Aprendidas             â”‚
â”‚ â€¢ Almacena episodios   â”‚ â€¢ Interfaz Gradio                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     MCP Server                              â”‚
â”‚            (Model Context Protocol)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Storage Backend (Strategy)                  â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚      â”‚         Local           â”‚       Server         â”‚     â”‚
â”‚      â”‚ (SQLite + ChromaDir)    â”‚ (ChromaDB Server)    â”‚     â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                Langfuse (Observabilidad)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Con pip (Recomendada)

```bash
# Clonar el repositorio
git clone https://github.com/JesusJimenez01/memorytwin.git
cd memorytwin

# Crear y activar entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Instalar Memory Twin
pip install -e .

# Configurar tu proyecto (crea .env, mcp.json, instrucciones)
mt setup

# Editar .env con tu API Key de Google Gemini
# ObtÃ©n una gratis en: https://aistudio.google.com/apikey
```

### OpciÃ³n 2: Con uv (MÃ¡s rÃ¡pido)

```bash
# Instalar uv si no lo tienes
pip install uv

# Clonar e instalar
git clone https://github.com/JesusJimenez01/memorytwin.git
cd memorytwin
uv venv && uv pip install -e .

# Configurar
uv run mt setup
```

### Â¡Listo!

DespuÃ©s de `mt setup`:
1. Edita `.env` y aÃ±ade tu `GOOGLE_API_KEY`
2. Reinicia VS Code
3. Copilot ahora usa Memory Twin automÃ¡ticamente ğŸ§ 

### Extras opcionales

```bash
# Interfaz web para explorar memorias
pip install -e ".[ui]"

# Todas las features
pip install -e ".[all]"

# Desarrollo (tests, linters)
pip install -e ".[all,dev]"
```

| Extra | DescripciÃ³n |
|-------|-------------|
| `ui` | Interfaz web Gradio |
| `observability` | Langfuse para trazabilidad |
| `openai` | Soporte para GPT |
| `anthropic` | Soporte para Claude |
| `all` | Todo incluido |
| `dev` | Herramientas de desarrollo |

## ğŸ”§ ConfiguraciÃ³n

El comando `mt setup` crea automÃ¡ticamente:

| Archivo | PropÃ³sito |
|---------|-----------|
| `.env` | Tu API Key y configuraciÃ³n |
| `.vscode/mcp.json` | IntegraciÃ³n con VS Code/Copilot |
| `.github/copilot-instructions.md` | Instrucciones para el agente |
| `.gitignore` | Ignora `.env` y `data/` |

### Variables de Entorno (.env)

```env
# Requerido: API Key de Google Gemini
# ObtÃ©n una gratis en: https://aistudio.google.com/apikey
GOOGLE_API_KEY=tu_api_key_aqui

# Opcional: Rutas de datos (por defecto usa ./data/)
# CHROMA_PERSIST_DIR=./data/chroma
# SQLITE_DB_PATH=./data/memory.db
```

## ğŸš€ Uso

### IntegraciÃ³n con VS Code y Copilot

DespuÃ©s de `mt setup` y reiniciar VS Code:
- Copilot tendrÃ¡ acceso a las herramientas de Memory Twin
- UsarÃ¡ automÃ¡ticamente la memoria del proyecto
- CapturarÃ¡ decisiones tÃ©cnicas importantes

#### Herramientas MCP Disponibles

| Herramienta | DescripciÃ³n |
|-------------|-------------|
| `get_project_context` | â­ **Principal**. Obtiene contexto del proyecto |
| `capture_thinking` | Captura razonamiento de decisiones |
| `query_memory` | Consultas RAG: "Â¿Por quÃ© elegimos X?" |
| `search_episodes` | BÃºsqueda semÃ¡ntica de episodios |
| `get_episode` | Contenido completo de un episodio |
| `get_lessons` | Lecciones aprendidas agregadas |
| `get_timeline` | Timeline cronolÃ³gico |
| `get_statistics` | EstadÃ­sticas de la memoria |
| `onboard_project` | AnÃ¡lisis inicial de proyecto |
| `consolidate_memories` | Crear meta-memorias |
| `check_consolidation_status` | Verificar si necesita consolidaciÃ³n |
| `mark_episode` | Marcar antipatterns/crÃ­ticos |

### CLI (LÃ­nea de Comandos)

```bash
# Configurar Memory Twin en tu proyecto
mt setup

# Buscar en la memoria
mt search "autenticaciÃ³n JWT"

# Consulta RAG (respuesta generada por LLM)
mt query "Â¿por quÃ© elegimos JWT para autenticaciÃ³n?"

# Ver lecciones aprendidas
mt lessons --project mi-proyecto

# Ver estadÃ­sticas
mt stats

# Consolidar memorias (crea meta-memorias)
mt consolidate --project mi-proyecto

# Verificar salud del sistema
mt health-check

# Analizar proyecto existente
mt onboard /ruta/proyecto

# Capturar pensamiento desde archivo
mt capture --file thinking.txt --project mi-proyecto
```

### Interfaz Web (requiere `pip install -e ".[ui]"`)

```bash
python -m memorytwin.oraculo.app
# Abre http://localhost:7860
```

## ğŸ§ª Tests

```bash
pip install -e ".[dev]"
pytest
```

## ğŸ“ Estructura del Proyecto

```
memorytwin/
â”œâ”€â”€ src/memorytwin/
â”‚   â”œâ”€â”€ escriba/            # Ingesta y CLI
â”‚   â”œâ”€â”€ oraculo/            # Consulta y Web UI
â”‚   â”œâ”€â”€ mcp_server/         # Servidor MCP
â”‚   â”œâ”€â”€ models.py           # Modelos de datos
â”‚   â”œâ”€â”€ scoring.py          # Sistema de relevancia
â”‚   â”œâ”€â”€ consolidation.py    # Meta-memorias
â”‚   â””â”€â”€ config.py           # ConfiguraciÃ³n
â”œâ”€â”€ data/                   # Datos persistentes
â”œâ”€â”€ tests/                  # Tests
â””â”€â”€ pyproject.toml          # Dependencias
```

## ğŸ“ˆ Escalabilidad

| Backend | Escala | Uso |
|---------|--------|-----|
| **ChromaDB Local** | ~1,000 episodios | Individual |
| **ChromaDB Server** | ~10,000 episodios | Equipos |
| **PostgreSQL** | ~100,000+ | ProducciÃ³n |
3. **CachÃ©**: Considera Redis para queries frecuentes
4. **Rate limiting**: Configura lÃ­mites de API en producciÃ³n

### Roadmap de escalabilidad

- [ ] Soporte PostgreSQL + pgvector
- [ ] Migraciones con Alembic
- [ ] CachÃ© inteligente con Redis
- [ ] Rate limiting configurable
- [ ] Archivado automÃ¡tico de episodios antiguos

## ğŸ§  Memoria Cognitiva Avanzada

Memory Twin incluye caracterÃ­sticas inspiradas en la neurociencia para gestionar la relevancia de las memorias.

### Sistema de Refuerzo (Sin Olvido)

A diferencia de sistemas que penalizan memorias antiguas, Memory Twin usa un enfoque de **"refuerzo sin olvido"**: todas las memorias persisten indefinidamente, pero las mÃ¡s consultadas ganan relevancia.

```
final_score = semantic_score Ã— boost Ã— importance_score Ã— modifiers
```

| Factor | FÃ³rmula | DescripciÃ³n |
|--------|---------|-------------|
| `semantic_score` | Similitud coseno | Relevancia semÃ¡ntica con la query |
| `boost` | `1 + 0.1 Ã— accesos` | Episodios consultados frecuentemente se refuerzan |
| `importance_score` | 0.0 - 1.0 | Relevancia base del episodio |
| `critical_modifier` | 1.5x | Episodios marcados como crÃ­ticos |
| `antipattern_modifier` | 0.3x | Antipatterns aparecen al final, no se excluyen |

**Beneficios del enfoque:**
- âœ… Las memorias antiguas pero valiosas nunca se "olvidan"
- âœ… El uso frecuente refuerza naturalmente lo importante
- âœ… Los antipatterns siguen visibles como advertencias
- âœ… Las meta-memorias consolidan patrones recurrentes

### Meta-Memorias (ConsolidaciÃ³n)

Similar a la consolidaciÃ³n de la memoria durante el sueÃ±o, Memory Twin puede **consolidar episodios relacionados en meta-memorias**:

```bash
# Consolidar episodios de un proyecto
mt consolidate --project mi-proyecto

# Con mÃ¡s detalle
mt consolidate --project mi-proyecto --verbose

# Ajustar mÃ­nimo de episodios por cluster
mt consolidate --project mi-proyecto --min-cluster 5
```

Una **MetaMemory** representa conocimiento consolidado:

| Campo | DescripciÃ³n |
|-------|-------------|
| `pattern` | PatrÃ³n comÃºn identificado |
| `lessons` | Lecciones aprendidas consolidadas |
| `best_practices` | Mejores prÃ¡cticas derivadas |
| `antipatterns` | Errores comunes a evitar |
| `exceptions` | Casos donde el patrÃ³n no aplica |
| `edge_cases` | Casos lÃ­mite descubiertos |
| `confidence` | Confianza en la consolidaciÃ³n (0-1) |
| `source_episode_ids` | IDs de episodios fuente |

**Proceso de consolidaciÃ³n:**
1. **Clustering**: Agrupa episodios similares usando DBSCAN sobre embeddings
2. **SÃ­ntesis**: Un LLM analiza el cluster y extrae patrones comunes
3. **Almacenamiento**: La meta-memoria se guarda con trazabilidad a episodios fuente

### IntegraciÃ³n en RAG

El sistema RAG prioriza las meta-memorias sobre episodios individuales:

1. **Buscar en meta-memorias** (conocimiento consolidado, mÃ¡s confiable)
2. **Complementar con episodios** (detalles especÃ­ficos)
3. **Combinar contexto** para generar respuesta

## ğŸ›¡ï¸ Resiliencia y RecuperaciÃ³n de Errores

### Fallos de API de LLM

Memory Twin incluye estrategias de retry automÃ¡tico para llamadas a LLM:

```python
# ConfiguraciÃ³n actual en processor.py
@retry(
    stop=stop_after_attempt(3),           # MÃ¡ximo 3 intentos
    wait=wait_exponential(min=2, max=10)  # Espera exponencial: 2s, 4s, 8s
)
async def process_thought(...):
```

**ConfiguraciÃ³n recomendada en `.env`:**

```env
# Rate limiting (prÃ³ximamente)
LLM_MAX_REQUESTS_PER_MINUTE=60
LLM_TIMEOUT_SECONDS=30

# Fallback a modelo local (prÃ³ximamente)
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_MODEL=ollama/llama3
```

### Consistencia de datos

Memory Twin usa almacenamiento dual (ChromaDB + SQLite). Para evitar inconsistencias:

```bash
# Verificar integridad de la base de datos
mt health-check
```

**Roadmap de mantenimiento (PrÃ³ximamente):**

```bash
# Sincronizar ChromaDB con SQLite
mt sync --repair

# Backup completo (SQLite + ChromaDB)
mt backup --output ./backups/$(date +%Y%m%d).tar.gz

# Restaurar desde backup
mt restore --input ./backups/20251127.tar.gz
```

### RecuperaciÃ³n de embeddings

Si los embeddings se corrompen o cambias de modelo (PrÃ³ximamente):

```bash
# Regenerar todos los embeddings desde SQLite
mt rebuild-embeddings

# Regenerar solo para un proyecto especÃ­fico
mt rebuild-embeddings --project mi-proyecto
```

### MigraciÃ³n de schemas

Para futuras migraciones de base de datos:

```bash
# Instalar dependencia de migraciones
pip install -e ".[sql]"

# Crear nueva migraciÃ³n
alembic revision --autogenerate -m "descripcion"

# Aplicar migraciones pendientes
alembic upgrade head

# Rollback a versiÃ³n anterior
alembic downgrade -1
```

### Roadmap de resiliencia

- [ ] Comando `mt backup/restore` para backups
- [ ] Comando `mt rebuild-embeddings` para regenerar vectores
- [ ] Transacciones atÃ³micas SQLite + ChromaDB
- [ ] Fallback a modelo local (Ollama)
- [ ] Migraciones con Alembic

## ğŸ“„ Licencia

MIT License

---

