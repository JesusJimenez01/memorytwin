# ğŸ§  The Memory Twin

> **Agente de Memoria EpisÃ³dica para Desarrollo de Software**

Sistema de arquitectura dual (Escriba + OrÃ¡culo) diseÃ±ado para mitigar la "amnesia tÃ©cnica" en equipos de desarrollo. Captura, procesa y almacena el razonamiento ("thinking") detrÃ¡s de las decisiones de cÃ³digo tomadas por asistentes de IA.

## ğŸ¯ Valor Diferencial

- **Memoria de Razonamiento**: Captura el "porquÃ©" (thinking), no solo el "quÃ©" (cÃ³digo final)
- **AgnÃ³stico del Modelo**: Funciona con cualquier asistente (Copilot, Claude, Cursor)
- **Onboarding Automatizado**: Reduce el tiempo de aprendizaje en proyectos legacy
- **RAG sobre Decisiones**: Consulta contextual sobre la historia tÃ©cnica
- **Colaborativo**: Soporte para base de datos compartida en equipos

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Memory Twin                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     ESCRIBA            â”‚           ORÃCULO                  â”‚
â”‚   (Backend/Ingesta)    â”‚       (Frontend/Consulta)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Captura thinking     â”‚ â€¢ Q&A Contextual (RAG)             â”‚
â”‚ â€¢ Procesa con LLM      â”‚ â€¢ Timeline de Decisiones           â”‚
â”‚ â€¢ Genera embeddings    â”‚ â€¢ Lecciones Aprendidas             â”‚
â”‚ â€¢ Almacena episodios   â”‚ â€¢ Interfaz Gradio                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     MCP Server                              â”‚
â”‚            (Model Context Protocol)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Storage Backend (Strategy)                  â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚      â”‚         Local           â”‚       Server         â”‚     â”‚
â”‚      â”‚ (SQLite + ChromaDir)    â”‚ (ChromaDB Server)    â”‚     â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                Langfuse (Observabilidad)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### 1. InstalaciÃ³n

```bash
# Clonar el repositorio
cd memorytwin

# Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# InstalaciÃ³n mÃ­nima (solo CLI y servidor MCP)
pip install -e .

# InstalaciÃ³n con interfaz web (OrÃ¡culo)
pip install -e ".[ui]"

# InstalaciÃ³n completa (todas las features)
pip install -e ".[all]"

# InstalaciÃ³n para desarrollo
pip install -e ".[all,dev]"
```

#### Dependencias opcionales disponibles:

| Extra | DescripciÃ³n | CuÃ¡ndo usarlo |
|-------|-------------|---------------|
| `ui` | Interfaz web Gradio (OrÃ¡culo) | Si quieres explorar memorias visualmente |
| `observability` | Langfuse para trazabilidad | Si necesitas monitoreo de LLM |
| `sql` | SQLAlchemy + Alembic | Para escalabilidad con PostgreSQL |
| `openai` | Proveedor OpenAI | Si usas GPT en lugar de Gemini |
| `anthropic` | Proveedor Anthropic | Si usas Claude en lugar de Gemini |
| `all` | Todas las features | InstalaciÃ³n completa |
| `dev` | Herramientas de desarrollo | Para contribuir al proyecto |

### 2. ConfiguraciÃ³n Inicial

Memory Twin incluye un comando de configuraciÃ³n automÃ¡tica que prepara tu entorno de desarrollo.

```bash
# Configura el entorno, crea archivos de configuraciÃ³n y prepara la integraciÃ³n con VS Code
mt setup
```

Este comando:
1.  Crea el archivo `.env` si no existe (deberÃ¡s editarlo con tu `GOOGLE_API_KEY`).
2.  Genera `.github/copilot-instructions.md` con las instrucciones para tu agente de IA.
3.  Genera `.vscode/mcp.json` configurado automÃ¡ticamente para usar el servidor MCP de Memory Twin en este proyecto.

### 3. Variables de Entorno

Edita el archivo `.env` generado con tus credenciales:

```env
# Requerido: API Key de Google Gemini
GOOGLE_API_KEY=tu_api_key_de_gemini

# Opcional: ConfiguraciÃ³n de Almacenamiento (por defecto 'local')
STORAGE_BACKEND=local
# STORAGE_BACKEND=chromadb_server
# CHROMA_SERVER_HOST=localhost
# CHROMA_SERVER_PORT=8000

# Opcional: Observabilidad con Langfuse
# LANGFUSE_PUBLIC_KEY=...
# LANGFUSE_SECRET_KEY=...
# LANGFUSE_HOST=...
```

## ğŸš€ Uso

### IntegraciÃ³n con VS Code y Copilot

Gracias al comando `mt setup`, tu VS Code ya deberÃ­a estar configurado.

1.  **Reinicia VS Code** para que cargue la configuraciÃ³n de MCP.
2.  Abre el chat de Copilot y verÃ¡s disponibles las herramientas de Memory Twin.
3.  Copilot usarÃ¡ automÃ¡ticamente estas herramientas siguiendo las instrucciones en `.github/copilot-instructions.md`.

#### Herramientas MCP Disponibles

| Herramienta | DescripciÃ³n |
|-------------|-------------|
| `get_project_context` | â­ **Principal**. Obtiene contexto inteligente del proyecto. Usar al inicio de cada tarea. |
| `capture_thinking` | Captura y almacena el razonamiento de decisiones tÃ©cnicas. |
| `query_memory` | Consulta memorias usando RAG. Ej: "Â¿Por quÃ© elegimos X?" |
| `search_episodes` | BÃºsqueda semÃ¡ntica de episodios por tÃ©rmino. |
| `get_episode` | Obtiene el contenido completo de un episodio por ID. |
| `get_lessons` | Obtiene lecciones aprendidas agregadas. |
| `get_timeline` | Timeline cronolÃ³gico de decisiones tÃ©cnicas. |
| `get_statistics` | EstadÃ­sticas de la base de memoria. |
| `onboard_project` | Analiza un proyecto existente y crea un episodio inicial. |

### CLI (LÃ­nea de Comandos)

Puedes usar el comando `mt` directamente en tu terminal:

```bash
# Capturar un pensamiento desde un archivo
mt capture --file thinking.txt --assistant copilot --project mi-proyecto

# Capturar desde el portapapeles
mt capture --clipboard --assistant claude

# Buscar en la memoria
mt search "autenticaciÃ³n JWT"

# Ver lecciones aprendidas
mt lessons --project mi-proyecto

# Ver estadÃ­sticas
mt stats --project mi-proyecto

# Consolidar memorias (Meta-Memorias)
mt consolidate --project mi-proyecto

# Verificar salud del sistema
mt health-check
```

### Onboarding de Proyectos Existentes

Si empiezas a trabajar en un proyecto que **ya existe** y no tiene historial en Memory Twin, puedes ejecutar un anÃ¡lisis inicial que crea una "memoria base" con la estructura, stack y convenciones del proyecto:

```bash
# Analizar el proyecto actual
mt onboard

# O especificar una ruta
mt onboard /ruta/a/mi-proyecto

# Ver el anÃ¡lisis completo
mt onboard --verbose
```

Esto genera un episodio de tipo "onboarding" que incluye:
- **Stack tecnolÃ³gico** detectado (Python, Node.js, etc.)
- **Patrones arquitectÃ³nicos** (MVC, DDD, etc.)
- **Dependencias principales**
- **Convenciones** de linting, testing, etc.

El agente de IA puede consultar esta informaciÃ³n para entender el proyecto desde el primer momento.

### Interfaz Web (OrÃ¡culo)

Para explorar la base de conocimiento visualmente:

```bash
# Iniciar interfaz web
python -m memorytwin.oraculo.app
# Abre http://localhost:7860
```

## ğŸ§ª Desarrollo y Tests

Para asegurar que todo funciona correctamente, puedes ejecutar los tests:

```bash
# Instalar dependencias de test
pip install pytest pytest-asyncio

# Ejecutar tests
pytest
```

## ğŸ“ Estructura del Proyecto

```
memorytwin/
â”œâ”€â”€ src/memorytwin/
â”‚   â”œâ”€â”€ escriba/            # Agente de Ingesta y CLI
â”‚   â”œâ”€â”€ oraculo/            # Agente de Consulta y Web UI
â”‚   â”œâ”€â”€ mcp_server/         # Servidor MCP
â”‚   â”œâ”€â”€ models.py           # Modelos de datos
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n
â”‚   â””â”€â”€ observability.py    # IntegraciÃ³n Langfuse
â”œâ”€â”€ scripts/                # Scripts de utilidad
â”œâ”€â”€ data/                   # Datos persistentes (modo local)
â”œâ”€â”€ tests/                  # Tests unitarios y de integraciÃ³n
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n del proyecto y dependencias
â””â”€â”€ README.md
```

## ğŸ“ˆ Escalabilidad

### Backends de almacenamiento

Memory Twin utiliza un patrÃ³n Strategy para el almacenamiento, permitiendo cambiar entre backends:

| Backend | Escala | Uso recomendado |
|---------|--------|-----------------|
| **ChromaDB Local** | ~1,000 episodios | Desarrollo individual |
| **ChromaDB Server** | ~10,000 episodios | Equipos pequeÃ±os |
| **PostgreSQL + pgvector** | ~100,000+ episodios | ProducciÃ³n / Equipos grandes |

```env
# Configurar backend en .env
STORAGE_BACKEND=local              # ChromaDB local (default)
STORAGE_BACKEND=chromadb_server    # ChromaDB Server
# STORAGE_BACKEND=postgresql       # PrÃ³ximamente
```

### Estrategias para escalar

1. **PaginaciÃ³n**: `get_project_context` usa enfoque hÃ­brido automÃ¡tico
2. **Archivado**: Episodios antiguos pueden moverse a almacenamiento frÃ­o
3. **CachÃ©**: Considera Redis para queries frecuentes
4. **Rate limiting**: Configura lÃ­mites de API en producciÃ³n

### Roadmap de escalabilidad

- [ ] Soporte PostgreSQL + pgvector
- [ ] Migraciones con Alembic
- [ ] CachÃ© inteligente con Redis
- [ ] Rate limiting configurable
- [ ] Archivado automÃ¡tico de episodios antiguos

## ğŸ§  Memoria Cognitiva Avanzada

Memory Twin incluye caracterÃ­sticas inspiradas en la neurociencia para simular el comportamiento de la memoria humana.

### Curva de Olvido (Forgetting Curve)

Inspirada en la curva de olvido de Ebbinghaus, los episodios tienen un **score hÃ­brido** que combina:

```
final_score = semantic_score Ã— decay Ã— boost Ã— importance_score
```

| Factor | FÃ³rmula | DescripciÃ³n |
|--------|---------|-------------|
| `semantic_score` | Similitud coseno | Relevancia semÃ¡ntica con la query |
| `decay` | `exp(-0.05 Ã— dÃ­as)` | Decaimiento temporal (episodios viejos se "olvidan") |
| `boost` | `1 + 0.1 Ã— accesos` | Episodios consultados frecuentemente se refuerzan |
| `importance_score` | 0.0 - 1.0 | Relevancia base del episodio |

**Ejemplo prÃ¡ctico:**
- Un episodio de hace 30 dÃ­as tiene ~22% de "frescura" (`exp(-0.05 Ã— 30) â‰ˆ 0.22`)
- Si fue consultado 10 veces, obtiene un boost de 2x (`1 + 0.1 Ã— 10 = 2.0`)
- Resultado: se mantiene relevante a pesar del tiempo

### Meta-Memorias (ConsolidaciÃ³n)

Similar a la consolidaciÃ³n de la memoria durante el sueÃ±o, Memory Twin puede **consolidar episodios relacionados en meta-memorias**:

```bash
# Consolidar episodios de un proyecto
mt consolidate --project mi-proyecto

# Con mÃ¡s detalle
mt consolidate --project mi-proyecto --verbose

# Ajustar mÃ­nimo de episodios por cluster
mt consolidate --project mi-proyecto --min-cluster 5
```

Una **MetaMemory** representa conocimiento consolidado:

| Campo | DescripciÃ³n |
|-------|-------------|
| `pattern` | PatrÃ³n comÃºn identificado |
| `lessons` | Lecciones aprendidas consolidadas |
| `best_practices` | Mejores prÃ¡cticas derivadas |
| `antipatterns` | Errores comunes a evitar |
| `exceptions` | Casos donde el patrÃ³n no aplica |
| `edge_cases` | Casos lÃ­mite descubiertos |
| `confidence` | Confianza en la consolidaciÃ³n (0-1) |
| `source_episode_ids` | IDs de episodios fuente |

**Proceso de consolidaciÃ³n:**
1. **Clustering**: Agrupa episodios similares usando DBSCAN sobre embeddings
2. **SÃ­ntesis**: Un LLM analiza el cluster y extrae patrones comunes
3. **Almacenamiento**: La meta-memoria se guarda con trazabilidad a episodios fuente

### IntegraciÃ³n en RAG

El sistema RAG prioriza las meta-memorias sobre episodios individuales:

1. **Buscar en meta-memorias** (conocimiento consolidado, mÃ¡s confiable)
2. **Complementar con episodios** (detalles especÃ­ficos)
3. **Combinar contexto** para generar respuesta

## ğŸ›¡ï¸ Resiliencia y RecuperaciÃ³n de Errores

### Fallos de API de LLM

Memory Twin incluye estrategias de retry automÃ¡tico para llamadas a LLM:

```python
# ConfiguraciÃ³n actual en processor.py
@retry(
    stop=stop_after_attempt(3),           # MÃ¡ximo 3 intentos
    wait=wait_exponential(min=2, max=10)  # Espera exponencial: 2s, 4s, 8s
)
async def process_thought(...):
```

**ConfiguraciÃ³n recomendada en `.env`:**

```env
# Rate limiting (prÃ³ximamente)
LLM_MAX_REQUESTS_PER_MINUTE=60
LLM_TIMEOUT_SECONDS=30

# Fallback a modelo local (prÃ³ximamente)
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_MODEL=ollama/llama3
```

### Consistencia de datos

Memory Twin usa almacenamiento dual (ChromaDB + SQLite). Para evitar inconsistencias:

```bash
# Verificar integridad de la base de datos
mt health-check
```

**Roadmap de mantenimiento (PrÃ³ximamente):**

```bash
# Sincronizar ChromaDB con SQLite
mt sync --repair

# Backup completo (SQLite + ChromaDB)
mt backup --output ./backups/$(date +%Y%m%d).tar.gz

# Restaurar desde backup
mt restore --input ./backups/20251127.tar.gz
```

### RecuperaciÃ³n de embeddings

Si los embeddings se corrompen o cambias de modelo (PrÃ³ximamente):

```bash
# Regenerar todos los embeddings desde SQLite
mt rebuild-embeddings

# Regenerar solo para un proyecto especÃ­fico
mt rebuild-embeddings --project mi-proyecto
```

### MigraciÃ³n de schemas

Para futuras migraciones de base de datos:

```bash
# Instalar dependencia de migraciones
pip install -e ".[sql]"

# Crear nueva migraciÃ³n
alembic revision --autogenerate -m "descripcion"

# Aplicar migraciones pendientes
alembic upgrade head

# Rollback a versiÃ³n anterior
alembic downgrade -1
```

### Roadmap de resiliencia

- [x] Retry automÃ¡tico con exponential backoff (LLM)
- [x] Comando `mt health-check` para verificar integridad
- [ ] Comando `mt backup/restore` para backups
- [ ] Comando `mt rebuild-embeddings` para regenerar vectores
- [ ] Transacciones atÃ³micas SQLite + ChromaDB
- [ ] Fallback a modelo local (Ollama)
- [ ] Migraciones con Alembic

## ğŸ“„ Licencia

MIT License

---

